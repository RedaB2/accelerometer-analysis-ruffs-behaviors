{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13809276,"sourceType":"datasetVersion","datasetId":8793224},{"sourceId":13811077,"sourceType":"datasetVersion","datasetId":8794177}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==========================================\n# FINAL FIXED PIPELINE (Robust Column Mapping)\n# ==========================================\nimport os\nimport glob\nimport sqlite3\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom prettytable import PrettyTable\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom scipy.signal import medfilt\nfrom scipy.stats import mode\nfrom numpy.lib.stride_tricks import sliding_window_view\nfrom sklearn.metrics import confusion_matrix, f1_score, classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\n\nwarnings.filterwarnings('ignore')\n\n# --- 1. CONFIGURATION ---\nclass Parameters:\n    def __init__(self):\n        self.db_path, self.labels_path = self.find_kaggle_files()\n        self.out_dir = \"/kaggle/working/output/\"\n        self.sw_length = 1.0\n        self.sampling_rate = 50\n        self.sw_overlap = 50\n        self.nb_channels = 3\n        \n        self.classes = {\n            'aggressive posturing': 0, 'being mounted': 1, 'copulation attempt': 2, \n            'dynamic squatting': 3, 'flying': 4, 'foraging or drinking': 5,\n            'mounting male': 6, 'other': 7, 'preening': 8, 'resting': 9, \n            'static squatting': 10, 'vigilance': 11, 'walking or running': 12\n        }\n        self.class_names = list(self.classes.keys())\n        self.nb_classes = len(self.classes)\n        \n        self.cv_fold_assignments = {\n            '1301': 0, '7-04-105': 1, '1361': 1, 'G20-0059-B6.5': 1,\n            'G20-0529-B6.5': 2, '952': 3, '1331': 4, 'G20-0071-B6.5': 4,\n            '1372': 5, '1326': 6, '1399': 7, '1681': 7, 'G20-0055-B6.5': 7,\n            '1368': 8, '1333': 9\n        }\n        self.folds_to_run = sorted(list(set(self.cv_fold_assignments.values())))\n        \n        self.nb_filters = 128        \n        self.filter_width = 11\n        self.nb_units_lstm = 256\n        self.nb_layers_lstm = 2      \n        self.drop_prob = 0.4         \n        self.batch_size = 256        \n        self.epochs = 60             \n        self.learning_rate = 1e-3    \n        self.weight_decay = 1e-4\n        self.gpu = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        self.weighted = True\n        self.train_excluding_transitions = True\n\n    def find_kaggle_files(self):\n        db_files = glob.glob(\"/kaggle/input/**/*.db\", recursive=True)\n        if not db_files: db_files = glob.glob(\"/kaggle/input/**/*.sqlite\", recursive=True)\n        csv_files = glob.glob(\"/kaggle/input/**/*.csv\", recursive=True)\n        # Find any CSV that looks like the labels file\n        labels_path = next((f for f in csv_files if \"behaviour\" in f.lower()), csv_files[0] if csv_files else None)\n        return db_files[0], labels_path\n\ndef seed_torch(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\ndef mkdir_if_missing(path):\n    if not os.path.exists(path): os.makedirs(path)\n\n# --- 2. ROBUST DATA LOADER ---\ndef load_dataset_joined(parameters):\n    print(f\"\\nðŸ“‚ Reading CSV: {parameters.labels_path}\")\n    labels_df = pd.read_csv(parameters.labels_path)\n    \n    # 1. Clean Columns\n    rename_map = {\n        'start_dt_real': 'start_time', 'Start (s)': 'start_time',\n        'stop_dt_real':  'stop_time',  'Stop (s)':  'stop_time',\n        'ruff_id': 'id', 'subject': 'id',\n        'behaviour': 'behavior', 'recording_id': 'rec_id_str'\n    }\n    labels_df = labels_df.rename(columns=rename_map)\n    \n    # Auto-detect recording column if missing\n    if 'rec_id_str' not in labels_df.columns:\n        rec_col = next((c for c in labels_df.columns if 'recording' in c), None)\n        if rec_col: labels_df.rename(columns={rec_col: 'rec_id_str'}, inplace=True)\n\n    labels_df['start_time'] = pd.to_datetime(labels_df['start_time'])\n    labels_df['stop_time'] = pd.to_datetime(labels_df['stop_time'])\n    labels_df['id'] = labels_df['id'].astype(str).str.strip()\n\n    conn = sqlite3.connect(parameters.db_path)\n    \n    # --- OPTIMIZATION: Pre-fetch Recording IDs ---\n    print(\"ðŸš€ Pre-fetching recording IDs to skip SQL JOINs...\")\n    rec_map_df = pd.read_sql_query(\"SELECT id, recording_id FROM recordings\", conn)\n    # Create dictionary: {'1372_L24_1': 1, ...}\n    rec_map = dict(zip(rec_map_df['recording_id'], rec_map_df['id']))\n    \n    data_list = []\n    print(\"â³ Querying DB (Direct Integer Lookup)...\")\n    \n    for _, row in tqdm(labels_df.iterrows(), total=len(labels_df)):\n        rec_str = row['rec_id_str']\n        \n        # Get Integer ID from our map (Fast!)\n        rec_int = rec_map.get(rec_str)\n        if rec_int is None: continue # Skip if mapping missing\n            \n        start = str(row['start_time'])\n        end = str(row['stop_time'])\n        \n        # OPTIMIZED QUERY: No JOIN, just direct integer lookup on Indexed column\n        query = f\"\"\"\n            SELECT datetime, accX, accY, accZ \n            FROM acc \n            WHERE recording_id = {rec_int} \n            AND datetime >= '{start}' AND datetime <= '{end}'\n        \"\"\"\n        try:\n            df = pd.read_sql_query(query, conn)\n            if not df.empty:\n                df['ruff_id'] = row['id']\n                df['behaviour'] = row['behavior']\n                data_list.append(df)\n        except: continue\n            \n    conn.close()\n    \n    if not data_list: raise ValueError(\"No segments found!\")\n    full_data = pd.concat(data_list, ignore_index=True)\n    \n    clean_map = {k.strip(): v for k, v in parameters.cv_fold_assignments.items()}\n    full_data = full_data.replace({'ruff_id': clean_map})\n    full_data.rename(columns={'ruff_id':'fold_id'}, inplace=True)\n    full_data.replace({'behaviour': parameters.classes}, inplace=True)\n    full_data['behaviour'] = pd.to_numeric(full_data['behaviour'], errors='coerce').dropna().astype(int)\n    full_data['fold_id'] = pd.to_numeric(full_data['fold_id'], errors='coerce').fillna(0).astype(int)\n    \n    print(f\"ðŸŽ‰ Loaded {len(full_data)} rows.\")\n    return full_data\n    \n# --- 3. PREPROCESSING ---\ndef apply_sliding_window(full_data, parameters):\n    w_len = int(parameters.sw_length * parameters.sampling_rate)\n    stride = int(w_len * (1 - (parameters.sw_overlap / 100)))\n    \n    X_raw = full_data[['accX', 'accY', 'accZ']].values.astype(np.float32)\n    y_raw = full_data['behaviour'].values.astype(np.int64)\n    folds_raw = full_data['fold_id'].values.astype(np.int64)\n    \n    list_x, list_y, list_trans, list_fold = [], [], [], []\n    print(\"Windowing...\")\n    for fold in np.unique(folds_raw):\n        mask = (folds_raw == fold)\n        curr_x, curr_y = X_raw[mask], y_raw[mask]\n        if len(curr_x) < w_len: continue\n        try:\n            win_x = sliding_window_view(curr_x, window_shape=w_len, axis=0)[::stride]\n            win_y = sliding_window_view(curr_y, window_shape=w_len, axis=0)[::stride]\n        except: continue\n        \n        if hasattr(mode(win_y, axis=1), 'mode'): y_final = mode(win_y, axis=1).mode.flatten()\n        else: y_final = mode(win_y, axis=1)[0].flatten()\n        \n        win_x = win_x.transpose(0, 2, 1)\n        list_x.append(win_x); list_y.append(y_final)\n        list_trans.append(mode(win_y, axis=1).count.flatten() != w_len)\n        list_fold.append(np.full(len(y_final), fold))\n        \n    return {\"win_X\": np.concatenate(list_x), \"win_y\": np.concatenate(list_y), \n            \"win_fold\": np.concatenate(list_fold), \"transition\": np.concatenate(list_trans)}\n\n# --- 4. DATASET & MODEL ---\nclass RuffDataset(Dataset):\n    def __init__(self, x, y, augment=False):\n        self.x = torch.from_numpy(x)\n        self.y = torch.from_numpy(y).long()\n        self.augment = augment\n    def __len__(self): return len(self.x)\n    def __getitem__(self, idx):\n        x, y = self.x[idx], self.y[idx]\n        if self.augment:\n            angle = np.random.uniform(-np.pi/4, np.pi/4)\n            rot = torch.tensor([[np.cos(angle), -np.sin(angle), 0], [np.sin(angle), np.cos(angle), 0], [0, 0, 1]], dtype=torch.float32)\n            x = torch.matmul(x, rot) + torch.randn_like(x) * 0.02\n        return x, y\n\nclass AttentionBlock(nn.Module):\n    def __init__(self, hidden_size):\n        super().__init__()\n        self.attention = nn.Linear(hidden_size, 1)\n    def forward(self, x):\n        w = F.softmax(self.attention(x), dim=1)\n        return torch.sum(w * x, dim=1)\n\nclass DeepConvLSTM_Attn(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.conv1 = nn.Sequential(nn.Conv2d(1, 64, (5, 1)), nn.BatchNorm2d(64), nn.ReLU())\n        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, (5, 1)), nn.BatchNorm2d(64), nn.ReLU())\n        self.conv3 = nn.Sequential(nn.Conv2d(64, 128, (5, 1)), nn.BatchNorm2d(128), nn.ReLU())\n        self.conv4 = nn.Sequential(nn.Conv2d(128, 128, (5, 1)), nn.BatchNorm2d(128), nn.ReLU())\n        self.lstm = nn.LSTM(128 * 3, config.nb_units_lstm, config.nb_layers_lstm, batch_first=True, dropout=0.2)\n        self.attn = AttentionBlock(config.nb_units_lstm)\n        self.fc = nn.Linear(config.nb_units_lstm, config.nb_classes)\n        self.seq_len = 50 - 4 * 4\n\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        x = self.conv4(self.conv3(self.conv2(self.conv1(x))))\n        x = x.permute(0, 2, 1, 3).reshape(x.size(0), self.seq_len, -1)\n        x, _ = self.lstm(x)\n        return self.fc(self.attn(x))\n\n# --- 5. EXECUTION ---\nif __name__ == \"__main__\":\n    p = Parameters()\n    mkdir_if_missing(p.out_dir)\n    seed_torch(42)\n    print(f\"ðŸš€ RUNNING PIPELINE | GPU: {p.gpu}\")\n\n    full_data = load_dataset_joined(p)\n    data = apply_sliding_window(full_data, p)\n    cv_scores, global_gt, global_preds = [], [], []\n    \n    print(\"\\n=== STARTING LSIO ===\")\n    for fold in p.folds_to_run:\n        print(f\"\\n>>> FOLD {fold}\")\n        \n        train_mask = (data['win_fold'] != fold)\n        if p.train_excluding_transitions: train_mask &= (~data['transition'])\n        val_mask = (data['win_fold'] == fold)\n        \n        X_tr, y_tr = data['win_X'][train_mask], data['win_y'][train_mask]\n        X_val, y_val = data['win_X'][val_mask], data['win_y'][val_mask]\n        if len(X_val) == 0: continue\n            \n        train_ds = RuffDataset(X_tr, y_tr, augment=True)\n        val_ds = RuffDataset(X_val, y_val, augment=False)\n        train_l = DataLoader(train_ds, batch_size=p.batch_size, shuffle=True, num_workers=2)\n        val_l = DataLoader(val_ds, batch_size=p.batch_size, shuffle=False, num_workers=2)\n        \n        net = DeepConvLSTM_Attn(p).to(p.gpu)\n        w_full = np.ones(p.nb_classes)\n        if p.weighted:\n            w = compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n            w_full[np.unique(y_tr)] = w\n        crit = nn.CrossEntropyLoss(weight=torch.FloatTensor(w_full).to(p.gpu))\n        opt = torch.optim.AdamW(net.parameters(), lr=p.learning_rate, weight_decay=p.weight_decay)\n        sched = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=p.learning_rate, steps_per_epoch=len(train_l), epochs=p.epochs)\n        \n        best_f1, best_preds = 0, None\n        for ep in range(p.epochs):\n            net.train()\n            losses = []\n            for x, y in train_l:\n                x, y = x.to(p.gpu), y.to(p.gpu)\n                opt.zero_grad()\n                loss = crit(net(x), y)\n                loss.backward()\n                opt.step()\n                sched.step()\n                losses.append(loss.item())\n                \n            net.eval()\n            preds, gt = [], []\n            with torch.no_grad():\n                for x, y in val_l:\n                    x = x.to(p.gpu)\n                    # TTA\n                    out1 = torch.softmax(net(x), dim=1)\n                    out2 = torch.softmax(net(x + torch.randn_like(x)*0.02), dim=1)\n                    preds.extend(np.argmax((out1+out2).cpu().numpy(), axis=1))\n                    gt.extend(y.numpy())\n            \n            f1 = f1_score(gt, preds, average='macro')\n            if f1 > best_f1: best_f1, best_preds = f1, preds\n            if ep % 5 == 0: print(f\"Ep {ep}: Loss {np.mean(losses):.4f} | Val F1 {f1:.4f}\")\n\n        smoothed = medfilt(best_preds, kernel_size=5)\n        final_f1 = f1_score(y_val, smoothed, average='macro')\n        cv_scores.append(final_f1)\n        print(f\"FOLD {fold} FINAL F1: {final_f1:.4f}\")\n        \n        global_gt.extend(y_val)\n        global_preds.extend(smoothed)\n        \n        # Save confusion matrix plot\n        cm = confusion_matrix(y_val, smoothed)\n        plt.figure(figsize=(8,6))\n        sns.heatmap(cm, cmap='Blues'); plt.title(f\"Fold {fold}\"); plt.savefig(f\"{p.out_dir}/cm_{fold}.png\"); plt.close()\n\n    print(f\"\\n=== MEAN F1: {np.mean(cv_scores):.4f} ===\")\n    print(classification_report(global_gt, global_preds, target_names=p.class_names))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==========================================\n# FINAL \"ULTRA-OPTIMIZED\" PIPELINE\n# Combines: Memory-Optimized Loading + Advanced Augmentation/TTA\n# ==========================================\nimport os\nimport glob\nimport gc\nimport sqlite3\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom prettytable import PrettyTable\n\n# Torch & Sklearn\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nfrom scipy.signal import medfilt\nfrom scipy.stats import mode\nfrom numpy.lib.stride_tricks import sliding_window_view\nfrom sklearn.metrics import confusion_matrix, f1_score, classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\n\nwarnings.filterwarnings('ignore')\n\n# ==========================================\n# 1. CONFIGURATION\n# ==========================================\nclass Parameters:\n    def __init__(self):\n        self.db_path, self.labels_path = self.find_kaggle_files()\n        self.out_dir = \"/kaggle/working/output/\"\n        \n        # Data Config\n        self.sw_length = 1.0\n        self.sampling_rate = 50\n        self.sw_overlap = 50\n        self.nb_channels = 3\n        \n        # Class Map\n        self.classes = {\n            'aggressive posturing': 0, 'being mounted': 1, 'copulation attempt': 2, \n            'dynamic squatting': 3, 'flying': 4, 'foraging or drinking': 5,\n            'mounting male': 6, 'other': 7, 'preening': 8, 'resting': 9, \n            'static squatting': 10, 'vigilance': 11, 'walking or running': 12\n        }\n        self.class_names = list(self.classes.keys())\n        self.nb_classes = len(self.classes)\n        \n        # 10-Fold Assignment\n        self.cv_fold_assignments = {\n            '1301': 0, '7-04-105': 1, '1361': 1, 'G20-0059-B6.5': 1,\n            'G20-0529-B6.5': 2, '952': 3, '1331': 4, 'G20-0071-B6.5': 4,\n            '1372': 5, '1326': 6, '1399': 7, '1681': 7, 'G20-0055-B6.5': 7,\n            '1368': 8, '1333': 9\n        }\n        self.folds_to_run = sorted(list(set(self.cv_fold_assignments.values())))\n        \n        # Optimized Hyperparameters\n        self.nb_filters = 64\n        self.filter_width = 11\n        self.nb_units_lstm = 256\n        self.nb_layers_lstm = 2      # Increased Depth for better representation\n        self.drop_prob = 0.5\n        self.batch_size = 512\n        self.epochs = 60             # Sufficient for OneCycleLR\n        self.learning_rate = 1e-3\n        self.weight_decay = 1e-5\n        self.gpu = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        # Flags\n        self.weighted = True\n        self.train_excluding_transitions = True\n\n    def find_kaggle_files(self):\n        print(\"ðŸ”Ž Searching for data...\")\n        db_files = glob.glob(\"/kaggle/input/**/*.db\", recursive=True)\n        if not db_files: db_files = glob.glob(\"/kaggle/input/**/*.sqlite\", recursive=True)\n        csv_files = glob.glob(\"/kaggle/input/**/*.csv\", recursive=True)\n        labels_path = next((f for f in csv_files if \"behaviour\" in f.lower()), csv_files[0] if csv_files else None)\n        return db_files[0], labels_path\n\ndef seed_torch(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\ndef mkdir_if_missing(path):\n    if not os.path.exists(path): os.makedirs(path)\n\n\n# ==========================================\n# 2. DATA PROCESSING (DEBUGGED & FIXED)\n# ==========================================\n\ndef create_dataset_optimized(parameters):\n    print(f\"\\nðŸ“‚ Reading CSV: {parameters.labels_path}\")\n    labels_df = pd.read_csv(parameters.labels_path)\n    \n    # 1. Normalize Columns\n    labels_df.columns = [c.strip().lower() for c in labels_df.columns]\n    print(f\"   Raw Columns: {labels_df.columns.tolist()}\")\n    \n    col_map = {}\n    \n    # --- STRICT PRIORITY MAPPING ---\n    # We look for the best match first. If found, we stop looking.\n    \n    # ID Column Priorities\n    id_candidates = ['ruff_id', 'individual_id', 'subject', 'id']\n    for c in id_candidates:\n        if c in labels_df.columns:\n            col_map[c] = 'id'\n            break\n            \n    # Behavior Column Priorities\n    beh_candidates = ['behaviour', 'behavior', 'activity']\n    for c in beh_candidates:\n        if c in labels_df.columns:\n            col_map[c] = 'behavior'\n            break\n            \n    # Start Time Priorities (Crucial Fix: Prioritize 'real' over 'video')\n    start_candidates = ['start_dt_real', 'start (s)', 'start_time', 'start']\n    for c in start_candidates:\n        if c in labels_df.columns:\n            col_map[c] = 'start_time'\n            break\n            \n    # Stop Time Priorities\n    stop_candidates = ['stop_dt_real', 'stop (s)', 'stop_time', 'stop', 'end']\n    for c in stop_candidates:\n        if c in labels_df.columns:\n            col_map[c] = 'stop_time'\n            break\n            \n    # Recording ID Priorities\n    rec_candidates = ['recording_id', 'rec_id', 'filename']\n    for c in rec_candidates:\n        if c in labels_df.columns:\n            col_map[c] = 'rec_id_str'\n            break\n    \n    print(f\"   Mapping Applied: {col_map}\")\n    \n    # Apply Rename\n    labels_df = labels_df.rename(columns=col_map)\n    \n    # Keep ONLY the columns we need (Drops duplicates/unused)\n    req_cols = ['id', 'behavior', 'start_time', 'stop_time', 'rec_id_str']\n    \n    # check missing\n    missing = [rc for rc in req_cols if rc not in labels_df.columns]\n    if missing:\n        raise KeyError(f\"Missing columns after mapping: {missing}\")\n        \n    # Filter DataFrame to just these 5 columns to prevent duplicates\n    labels_df = labels_df[req_cols].copy()\n\n    # 2. Convert Types\n    labels_df['start_time'] = pd.to_datetime(labels_df['start_time'])\n    labels_df['stop_time'] = pd.to_datetime(labels_df['stop_time'])\n    labels_df['rec_id_str'] = labels_df['rec_id_str'].astype(str).str.strip()\n    labels_df['id'] = labels_df['id'].astype(str).str.strip()\n\n    # 3. Prepare Mappings\n    fold_map = {k.strip(): v for k, v in parameters.cv_fold_assignments.items()}\n    \n    conn = sqlite3.connect(parameters.db_path)\n    try:\n        rec_map_df = pd.read_sql_query(\"SELECT id, recording_id FROM recordings\", conn)\n        rec_int_map = dict(zip(rec_map_df['recording_id'], rec_map_df['id']))\n    except:\n        raise ValueError(\"Could not map recordings! Check DB schema.\")\n    \n    # 4. Setup Windowing\n    w_len = int(parameters.sw_length * parameters.sampling_rate)\n    stride = int(w_len * (1 - (parameters.sw_overlap / 100)))\n    \n    master_X, master_y, master_fold, master_trans = [], [], [], []\n    \n    grouped = labels_df.groupby('rec_id_str')\n    print(f\"ðŸš€ Processing {len(grouped)} recordings...\")\n    \n    for rec_str, group in tqdm(grouped):\n        rec_int = rec_int_map.get(rec_str)\n        if rec_int is None: continue\n            \n        min_t = group['start_time'].min()\n        max_t = group['stop_time'].max()\n        \n        query = f\"\"\"\n            SELECT datetime, accX, accY, accZ \n            FROM acc \n            WHERE recording_id = {rec_int} \n            AND datetime >= '{min_t}' AND datetime <= '{max_t}'\n        \"\"\"\n        try:\n            rec_df = pd.read_sql_query(query, conn)\n            if rec_df.empty: continue\n            rec_df['datetime'] = pd.to_datetime(rec_df['datetime'])\n            rec_df = rec_df.sort_values('datetime')\n        except: continue\n            \n        for _, row in group.iterrows():\n            mask = (rec_df['datetime'] >= row['start_time']) & (rec_df['datetime'] <= row['stop_time'])\n            segment = rec_df[mask]\n            \n            if len(segment) < w_len: continue\n                \n            x_raw = segment[['accX', 'accY', 'accZ']].values.astype(np.float32)\n            bird_id = row['id']\n            fold_id = fold_map.get(bird_id, -1)\n            label = parameters.classes.get(row['behavior'], -1)\n            \n            if fold_id == -1 or label == -1: continue\n            \n            try:\n                wins = sliding_window_view(x_raw, window_shape=w_len, axis=0)[::stride]\n                wins = wins.transpose(0, 2, 1) # (N, 50, 3)\n                \n                n = len(wins)\n                master_X.append(wins)\n                master_y.append(np.full(n, label, dtype=np.int64))\n                master_fold.append(np.full(n, fold_id, dtype=np.int64))\n                master_trans.append(np.zeros(n, dtype=bool))\n            except: continue\n        \n        del rec_df\n        gc.collect()\n\n    conn.close()\n    \n    if not master_X: raise ValueError(\"No data created! Check mappings.\")\n    \n    print(\"Concatenating...\")\n    return {\n        \"win_X\": np.concatenate(master_X, axis=0),\n        \"win_y\": np.concatenate(master_y, axis=0),\n        \"win_fold\": np.concatenate(master_fold, axis=0),\n        \"transition\": np.concatenate(master_trans, axis=0)\n    }\n    \n# ==========================================\n# 3. DATASET WITH AUGMENTATION\n# ==========================================\nclass RuffDataset(Dataset):\n    def __init__(self, x, y, augment=False):\n        self.x = torch.from_numpy(x)\n        self.y = torch.from_numpy(y).long()\n        self.augment = augment\n\n    def __len__(self): return len(self.x)\n\n    def __getitem__(self, idx):\n        x, y = self.x[idx], self.y[idx]\n        if self.augment:\n            # Random Rotation\n            angle = np.random.uniform(-np.pi/6, np.pi/6)\n            c, s = np.cos(angle), np.sin(angle)\n            rot = torch.tensor([[c, -s, 0], [s, c, 0], [0, 0, 1]], dtype=torch.float32)\n            x = torch.matmul(x, rot)\n            # Noise\n            x += torch.randn_like(x) * 0.01\n        return x, y\n\n# ==========================================\n# 4. MODEL (DeepConvLSTM+)\n# ==========================================\nclass DeepConvLSTM(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.nb_filters = config.nb_filters\n        self.nb_classes = config.nb_classes\n        \n        # 2 Conv Blocks + Batch Norm\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, 64, (11, 1)),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(64, 64, (11, 1)),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True)\n        )\n        \n        self.final_seq_len = 50 - (11-1)*2\n        self.lstm = nn.LSTM(64*3, config.nb_units_lstm, config.nb_layers_lstm, batch_first=True, dropout=0.5)\n        self.fc = nn.Linear(config.nb_units_lstm, self.nb_classes)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        x = self.conv2(self.conv1(x))\n        x = x.permute(0, 2, 1, 3).reshape(x.size(0), -1, 64*3)\n        x, _ = self.lstm(x)\n        return self.fc(x[:, -1, :])\n\ndef init_weights(m):\n    if isinstance(m, (nn.Conv2d, nn.Linear)): nn.init.xavier_normal_(m.weight)\n    if isinstance(m, nn.LSTM): \n        for n, p in m.named_parameters():\n            if 'weight' in n: nn.init.xavier_normal_(p)\n\n# ==========================================\n# 5. VISUALIZATION UTILS\n# ==========================================\ndef plot_metrics(history, fold, out_dir):\n    plt.figure(figsize=(10,5))\n    plt.plot(history['loss'], label='Train Loss', color='red')\n    plt.twinx().plot(history['f1'], label='Val F1', color='blue')\n    plt.title(f\"Fold {fold} Training\")\n    plt.legend()\n    plt.savefig(f\"{out_dir}/curve_{fold}.png\")\n    plt.close()\n\n# ==========================================\n# 6. MAIN EXECUTION\n# ==========================================\nif __name__ == \"__main__\":\n    p = Parameters()\n    mkdir_if_missing(p.out_dir)\n    seed_torch(42)\n    print(f\"ðŸš€ RUNNING OPTIMIZED PIPELINE | GPU: {p.gpu}\")\n\n    # 1. Create Data\n    data = create_dataset_optimized(p)\n    print(f\"âœ… Dataset Ready: {len(data['win_y'])} windows\")\n    \n    cv_scores, global_gt, global_preds = [], [], []\n    \n    print(\"\\n=== STARTING LSIO ===\")\n    for fold in p.folds_to_run:\n        print(f\"\\n>>> FOLD {fold}\")\n        \n        train_mask = (data['win_fold'] != fold)\n        if p.train_excluding_transitions: train_mask &= (~data['transition'])\n        val_mask = (data['win_fold'] == fold)\n        \n        X_tr, y_tr = data['win_X'][train_mask], data['win_y'][train_mask]\n        X_val, y_val = data['win_X'][val_mask], data['win_y'][val_mask]\n        \n        if len(X_val) == 0: continue\n            \n        # Augmentation on Train, No Aug on Val\n        train_ds = RuffDataset(X_tr, y_tr, augment=True)\n        val_ds = RuffDataset(X_val, y_val, augment=False)\n        \n        train_l = DataLoader(train_ds, batch_size=p.batch_size, shuffle=True, num_workers=2)\n        val_l = DataLoader(val_ds, batch_size=p.batch_size, shuffle=False, num_workers=2)\n        \n        net = DeepConvLSTM(p).to(p.gpu)\n        net.apply(init_weights)\n        \n        # Weighted Loss\n        w_full = np.ones(p.nb_classes)\n        if p.weighted and len(y_tr) > 0:\n            w = compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n            w_full[np.unique(y_tr)] = w\n        crit = nn.CrossEntropyLoss(weight=torch.FloatTensor(w_full).to(p.gpu))\n        \n        opt = torch.optim.AdamW(net.parameters(), lr=p.learning_rate, weight_decay=p.weight_decay)\n        sched = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=p.learning_rate, steps_per_epoch=len(train_l), epochs=p.epochs)\n        \n        best_f1, best_preds = 0, None\n        history = {'loss': [], 'f1': []}\n        \n        for ep in range(p.epochs):\n            net.train()\n            losses = []\n            for x, y in train_l:\n                x, y = x.to(p.gpu), y.to(p.gpu)\n                opt.zero_grad()\n                loss = crit(net(x), y)\n                loss.backward()\n                opt.step()\n                sched.step()\n                losses.append(loss.item())\n                \n            # TTA VALIDATION\n            net.eval()\n            preds, gt = [], []\n            with torch.no_grad():\n                for x, y in val_l:\n                    x = x.to(p.gpu)\n                    # TTA: Normal + Noisy\n                    out1 = torch.softmax(net(x), dim=1)\n                    out2 = torch.softmax(net(x + torch.randn_like(x)*0.01), dim=1)\n                    avg = (out1 + out2) / 2\n                    preds.extend(np.argmax(avg.cpu().numpy(), axis=1))\n                    gt.extend(y.numpy())\n            \n            f1 = f1_score(gt, preds, average='macro')\n            history['loss'].append(np.mean(losses))\n            history['f1'].append(f1)\n            \n            if f1 > best_f1: best_f1, best_preds = f1, preds\n            if ep % 10 == 0: print(f\"Ep {ep}: Loss {np.mean(losses):.4f} | Val F1 {f1:.4f}\")\n\n        # Smoothing\n        smoothed = medfilt(best_preds, kernel_size=5)\n        final_f1 = f1_score(y_val, smoothed, average='macro')\n        cv_scores.append(final_f1)\n        print(f\"FOLD {fold} FINAL F1: {final_f1:.4f}\")\n        \n        # Store & Save\n        global_gt.extend(y_val)\n        global_preds.extend(smoothed)\n        plot_metrics(history, fold, p.out_dir)\n        \n        cm = confusion_matrix(y_val, smoothed)\n        plt.figure(figsize=(8,6))\n        sns.heatmap(cm, cmap='Blues'); plt.title(f\"Fold {fold}\"); plt.savefig(f\"{p.out_dir}/cm_{fold}.png\"); plt.close()\n\n    print(f\"\\n=== MEAN F1: {np.mean(cv_scores):.4f} ===\")\n    print(classification_report(global_gt, global_preds, target_names=p.class_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T14:46:32.306400Z","iopub.execute_input":"2025-11-25T14:46:32.306640Z","iopub.status.idle":"2025-11-25T16:50:26.545372Z","shell.execute_reply.started":"2025-11-25T14:46:32.306618Z","shell.execute_reply":"2025-11-25T16:50:26.544508Z"}},"outputs":[{"name":"stdout","text":"ðŸ”Ž Searching for data...\nðŸš€ RUNNING OPTIMIZED PIPELINE | GPU: cuda\n\nðŸ“‚ Reading CSV: /kaggle/input/ruff-behaviour-data/ruff_behaviour_tidy_2022-11-16.csv\n   Raw Columns: ['beh_event_id', 'recording_id', 'video_analysis_id', 'ruff_id', 'ruff_name', 'morph', 'video_file_start_dt', 'video_start_secs', 'video_stop_secs', 'start_dt_real', 'stop_dt_real', 'duration_secs', 'behaviour']\n   Mapping Applied: {'ruff_id': 'id', 'behaviour': 'behavior', 'start_dt_real': 'start_time', 'stop_dt_real': 'stop_time', 'recording_id': 'rec_id_str'}\nðŸš€ Processing 28 recordings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29a70956a8714622bae9633983be235e"}},"metadata":{}},{"name":"stdout","text":"Concatenating...\nâœ… Dataset Ready: 136622 windows\n\n=== STARTING LSIO ===\n\n>>> FOLD 0\nEp 0: Loss 2.1102 | Val F1 0.1946\nEp 10: Loss 1.2558 | Val F1 0.3854\nEp 20: Loss 1.0270 | Val F1 0.2713\nEp 30: Loss 0.8152 | Val F1 0.3437\nEp 40: Loss 0.6145 | Val F1 0.4028\nEp 50: Loss 0.5081 | Val F1 0.3891\nFOLD 0 FINAL F1: 0.4287\n\n>>> FOLD 1\nEp 0: Loss 2.1218 | Val F1 0.2224\nEp 10: Loss 1.2380 | Val F1 0.2700\nEp 20: Loss 1.0314 | Val F1 0.2948\nEp 30: Loss 0.7481 | Val F1 0.3648\nEp 40: Loss 0.5954 | Val F1 0.3692\nEp 50: Loss 0.4841 | Val F1 0.3490\nFOLD 1 FINAL F1: 0.4022\n\n>>> FOLD 2\nEp 0: Loss 2.0996 | Val F1 0.2679\nEp 10: Loss 1.2169 | Val F1 0.2836\nEp 20: Loss 0.9761 | Val F1 0.3501\nEp 30: Loss 0.7453 | Val F1 0.3294\nEp 40: Loss 0.5574 | Val F1 0.3438\nEp 50: Loss 0.4481 | Val F1 0.3594\nFOLD 2 FINAL F1: 0.3653\n\n>>> FOLD 3\nEp 0: Loss 2.1185 | Val F1 0.2523\nEp 10: Loss 1.2086 | Val F1 0.3056\nEp 20: Loss 0.9718 | Val F1 0.3542\nEp 30: Loss 0.7788 | Val F1 0.3202\nEp 40: Loss 0.5912 | Val F1 0.3359\nEp 50: Loss 0.4845 | Val F1 0.3763\nFOLD 3 FINAL F1: 0.4298\n\n>>> FOLD 4\nEp 0: Loss 2.0967 | Val F1 0.1834\nEp 10: Loss 1.2181 | Val F1 0.2625\nEp 20: Loss 0.9627 | Val F1 0.3083\nEp 30: Loss 0.7546 | Val F1 0.3055\nEp 40: Loss 0.5822 | Val F1 0.3374\nEp 50: Loss 0.4756 | Val F1 0.3424\nFOLD 4 FINAL F1: 0.3635\n\n>>> FOLD 5\nEp 0: Loss 2.0945 | Val F1 0.0886\nEp 10: Loss 1.1835 | Val F1 0.1854\nEp 20: Loss 0.9431 | Val F1 0.1301\nEp 30: Loss 0.7535 | Val F1 0.1499\nEp 40: Loss 0.5710 | Val F1 0.1511\nEp 50: Loss 0.4622 | Val F1 0.1812\nFOLD 5 FINAL F1: 0.2114\n\n>>> FOLD 6\nEp 0: Loss 2.0910 | Val F1 0.3099\nEp 10: Loss 1.2605 | Val F1 0.2749\nEp 20: Loss 1.0235 | Val F1 0.3234\nEp 30: Loss 0.7773 | Val F1 0.4468\nEp 40: Loss 0.6164 | Val F1 0.4139\nEp 50: Loss 0.5026 | Val F1 0.4432\nFOLD 6 FINAL F1: 0.4940\n\n>>> FOLD 7\nEp 0: Loss 2.0911 | Val F1 0.2471\nEp 10: Loss 1.2138 | Val F1 0.2649\nEp 20: Loss 0.9690 | Val F1 0.2781\nEp 30: Loss 0.7429 | Val F1 0.3006\nEp 40: Loss 0.5932 | Val F1 0.3276\nEp 50: Loss 0.4828 | Val F1 0.3609\nFOLD 7 FINAL F1: 0.3622\n\n>>> FOLD 8\nEp 0: Loss 2.1206 | Val F1 0.2824\nEp 10: Loss 1.2718 | Val F1 0.2214\nEp 20: Loss 1.0387 | Val F1 0.4182\nEp 30: Loss 0.7926 | Val F1 0.3109\nEp 40: Loss 0.5995 | Val F1 0.3432\nEp 50: Loss 0.5043 | Val F1 0.3649\nFOLD 8 FINAL F1: 0.4794\n\n>>> FOLD 9\nEp 0: Loss 2.1004 | Val F1 0.2569\nEp 10: Loss 1.2090 | Val F1 0.3109\nEp 20: Loss 0.9614 | Val F1 0.3453\nEp 30: Loss 0.7161 | Val F1 0.3708\nEp 40: Loss 0.5703 | Val F1 0.3866\nEp 50: Loss 0.4617 | Val F1 0.3910\nFOLD 9 FINAL F1: 0.3968\n\n=== MEAN F1: 0.3933 ===\n                      precision    recall  f1-score   support\n\naggressive posturing       0.79      0.34      0.47     10342\n       being mounted       0.27      0.52      0.35       278\n  copulation attempt       0.05      0.08      0.06       306\n   dynamic squatting       0.16      0.48      0.24      2423\n              flying       0.85      0.95      0.90      2088\nforaging or drinking       0.43      0.62      0.51      7056\n       mounting male       0.11      0.38      0.17       384\n               other       0.16      0.24      0.20      2749\n            preening       0.81      0.78      0.80     23116\n             resting       0.60      0.64      0.62     24039\n    static squatting       0.37      0.45      0.41     15152\n           vigilance       0.68      0.62      0.65     32384\n  walking or running       0.79      0.48      0.59     16305\n\n            accuracy                           0.59    136622\n           macro avg       0.47      0.51      0.46    136622\n        weighted avg       0.64      0.59      0.60    136622\n\n","output_type":"stream"}],"execution_count":1}]}